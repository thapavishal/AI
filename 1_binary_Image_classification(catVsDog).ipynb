{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "001_Image_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6R7dRAVgfH6",
        "outputId": "5c88ab99-8a79-48e0-e590-8a02b6374f25"
      },
      "source": [
        "cd /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmeoiGithLcy"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv2D\r\n",
        "from keras.layers import MaxPooling2D, Flatten, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oALv2LblhRNd"
      },
      "source": [
        "model = Sequential()\r\n",
        "# step1-Convolution\r\n",
        "model.add(Conv2D(256,(3,3),input_shape=(64, 64, 3),activation='relu'))\r\n",
        "# step2-Maxpooling\r\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZYwdx9qhVJv"
      },
      "source": [
        "# Adding second convolutionsl layer\r\n",
        "# step1-Convolution\r\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\r\n",
        "# step2-Maxpooling\r\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2V1U3F0hXX6"
      },
      "source": [
        "# Adding third convolutionsl layer\r\n",
        "# step1-Convolution\r\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\r\n",
        "# step2-Maxpooling\r\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\r\n",
        "\r\n",
        "model.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UGDKgoLhc6q",
        "outputId": "ed5b272f-8774-448b-d4e8-6ec0b07c4650"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 62, 62, 256)       7168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 31, 31, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 29, 29, 128)       295040    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 64)        73792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "=================================================================\n",
            "Total params: 376,000\n",
            "Trainable params: 376,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps6tCqKxhf1x"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   width_shift_range = 0.3,\r\n",
        "                                   height_shift_range = 0.3,\r\n",
        "                                   zoom_range = 0.2,\r\n",
        "                                   horizontal_flip = True,\r\n",
        "                                   fill_mode = 'nearest' \r\n",
        "                                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh9lCwElhyGD"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_39J1i8h1X1",
        "outputId": "9b5a13d5-9846-43b1-c717-c42e6724daff"
      },
      "source": [
        "batch_size = 128\r\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/dogvscat/archive/training_set/training_set',\r\n",
        "                                                 target_size=(64,64),\r\n",
        "                                                 batch_size = batch_size,\r\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8005 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2ZnUCDsh5vm",
        "outputId": "c3f2fa0d-d19f-4126-c073-551dadedbe95"
      },
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/dogvscat/archive/test_set/test_set',\r\n",
        "                                                 target_size=(64,64),\r\n",
        "                                                 batch_size = batch_size,\r\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2023 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oWjiL3XiBNO"
      },
      "source": [
        "# full connection\r\n",
        "model.add(Dense(units=256,activation='relu'))\r\n",
        "model.add(Dense(units=128,activation='relu'))\r\n",
        "model.add(Dense(units = 64,activation='relu'))\r\n",
        "model.add(Dense(units = 16,activation='relu'))\r\n",
        "# model.add(Dense(units = 16,activation='relu'))\r\n",
        "model.add(Dense(units = 1,activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ3EbyW9iLq5"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b6vuwfMihNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9783a863-1f1b-4b5d-a3ef-80b6745fbe03"
      },
      "source": [
        "history = model.fit(training_set,\r\n",
        "          steps_per_epoch = 8005//batch_size,\r\n",
        "          validation_data = test_set,\r\n",
        "          validation_steps = 2023//batch_size,\r\n",
        "          epochs = 20)\r\n",
        "model.save('/content/drive/MyDrive/dogvscat/cat_vs_dogV3.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "62/62 [==============================] - 2656s 43s/step - loss: 0.6933 - accuracy: 0.5062 - val_loss: 0.6744 - val_accuracy: 0.6026\n",
            "Epoch 2/20\n",
            "62/62 [==============================] - 379s 6s/step - loss: 0.6698 - accuracy: 0.5833 - val_loss: 0.6618 - val_accuracy: 0.6229\n",
            "Epoch 3/20\n",
            "62/62 [==============================] - 376s 6s/step - loss: 0.6654 - accuracy: 0.5959 - val_loss: 0.6367 - val_accuracy: 0.6401\n",
            "Epoch 4/20\n",
            "62/62 [==============================] - 377s 6s/step - loss: 0.6499 - accuracy: 0.6147 - val_loss: 0.6550 - val_accuracy: 0.6224\n",
            "Epoch 5/20\n",
            "62/62 [==============================] - 379s 6s/step - loss: 0.6404 - accuracy: 0.6267 - val_loss: 0.6465 - val_accuracy: 0.6583\n",
            "Epoch 6/20\n",
            "62/62 [==============================] - 375s 6s/step - loss: 0.6337 - accuracy: 0.6353 - val_loss: 0.6073 - val_accuracy: 0.6693\n",
            "Epoch 7/20\n",
            "62/62 [==============================] - 378s 6s/step - loss: 0.6336 - accuracy: 0.6332 - val_loss: 0.5877 - val_accuracy: 0.6953\n",
            "Epoch 8/20\n",
            "62/62 [==============================] - 379s 6s/step - loss: 0.6079 - accuracy: 0.6663 - val_loss: 0.6036 - val_accuracy: 0.6677\n",
            "Epoch 9/20\n",
            "62/62 [==============================] - 378s 6s/step - loss: 0.6104 - accuracy: 0.6606 - val_loss: 0.5619 - val_accuracy: 0.7151\n",
            "Epoch 10/20\n",
            "62/62 [==============================] - 378s 6s/step - loss: 0.5911 - accuracy: 0.6821 - val_loss: 0.5519 - val_accuracy: 0.7161\n",
            "Epoch 11/20\n",
            "62/62 [==============================] - 375s 6s/step - loss: 0.5822 - accuracy: 0.6963 - val_loss: 0.5349 - val_accuracy: 0.7380\n",
            "Epoch 12/20\n",
            "62/62 [==============================] - 379s 6s/step - loss: 0.5679 - accuracy: 0.7114 - val_loss: 0.5724 - val_accuracy: 0.6917\n",
            "Epoch 13/20\n",
            "62/62 [==============================] - 378s 6s/step - loss: 0.5612 - accuracy: 0.7125 - val_loss: 0.5795 - val_accuracy: 0.7193\n",
            "Epoch 14/20\n",
            "62/62 [==============================] - 376s 6s/step - loss: 0.5440 - accuracy: 0.7175 - val_loss: 0.4834 - val_accuracy: 0.7776\n",
            "Epoch 15/20\n",
            "62/62 [==============================] - 380s 6s/step - loss: 0.5187 - accuracy: 0.7475 - val_loss: 0.5189 - val_accuracy: 0.7411\n",
            "Epoch 16/20\n",
            "62/62 [==============================] - 380s 6s/step - loss: 0.5192 - accuracy: 0.7469 - val_loss: 0.5652 - val_accuracy: 0.7365\n",
            "Epoch 17/20\n",
            "62/62 [==============================] - 375s 6s/step - loss: 0.5110 - accuracy: 0.7569 - val_loss: 0.4496 - val_accuracy: 0.7958\n",
            "Epoch 18/20\n",
            "62/62 [==============================] - 378s 6s/step - loss: 0.5065 - accuracy: 0.7480 - val_loss: 0.4889 - val_accuracy: 0.7490\n",
            "Epoch 19/20\n",
            "62/62 [==============================] - 377s 6s/step - loss: 0.5093 - accuracy: 0.7572 - val_loss: 0.4734 - val_accuracy: 0.7792\n",
            "Epoch 20/20\n",
            "62/62 [==============================] - 380s 6s/step - loss: 0.5176 - accuracy: 0.7472 - val_loss: 0.4126 - val_accuracy: 0.8120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y12H0x07RG6s",
        "outputId": "a32b431d-ed8f-4793-c6d5-b9dc87cd0891"
      },
      "source": [
        "import numpy as np\r\n",
        "from keras.preprocessing import image\r\n",
        "test_image = image.load_img('/content/drive/MyDrive/dogvscat/archive/test_set/test_set/cats/cat.4001.jpg', target_size=(64,64))\r\n",
        "test_image = image.img_to_array(test_image)\r\n",
        "test_image = np.expand_dims(test_image, axis = 0)\r\n",
        "result = model.predict(test_image)\r\n",
        "result [0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.129976"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJLIRQBoROR4",
        "outputId": "a58767f8-f426-4c8b-850e-1bedfd835045"
      },
      "source": [
        "if result [0][0] >= 2.12:\r\n",
        "  prediction = 'cat'\r\n",
        "  print(prediction)\r\n",
        "else:\r\n",
        "  prediction = 'dog'\r\n",
        "  print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFMcC9YRSnX"
      },
      "source": [
        "# Plot of training loss VS validation Loss\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "history_dict= history.history\r\n",
        "print(history_dict)\r\n",
        "loss_values = history_dict['loss']\r\n",
        "val_loss_values = history_dict['val_loss']\r\n",
        "epochs = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\r\n",
        "line1 = plt.plot(epochs,val_loss_values,label = 'Validation/Test Loss')\r\n",
        "line2 = plt.plot(epochs,loss_values,label = 'Training Loss')\r\n",
        "\r\n",
        "plt.setp(line1,linewidth = 3.0,marker = '+',markersize = 10.0)\r\n",
        "plt.setp(line2,linewidth = 3.0,marker ='4',markersize = 10.0)\r\n",
        "\r\n",
        "plt.xlabel('No of Epochs')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.grid(True)\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VAFbs0cRVnA"
      },
      "source": [
        "# accuracy plot\r\n",
        "# Plot of training acc VS validation acc\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "history_dict= history.history\r\n",
        "acc_values = history_dict['accuracy']\r\n",
        "val_acc_values = history_dict['val_accuracy']\r\n",
        "line1 = plt.plot(epochs,acc_values,label = 'Validation/Test Acc')\r\n",
        "line2 = plt.plot(epochs,val_acc_values,label = 'Training Acc')\r\n",
        "\r\n",
        "plt.setp(line1,linewidth = 3,marker = '+',markersize = 7)\r\n",
        "plt.setp(line2,linewidth = 3,marker = '*',markersize = 7)\r\n",
        "\r\n",
        "plt.xlabel('No of Epochs')\r\n",
        "plt.ylabel('Acc')\r\n",
        "plt.grid(True)\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVuBs0ZARZNi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}